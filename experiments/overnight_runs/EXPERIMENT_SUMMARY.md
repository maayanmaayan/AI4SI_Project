# Overnight Experiments Summary

**Date:** January 19-20, 2026  
**Total Experiments:** 9  
**Total Runtime:** ~7.9 hours  
**All Experiments:** ‚úÖ Completed Successfully

---

## Executive Summary

This document summarizes 9 experiments conducted to address mode collapse and uniform prediction issues in the Graph Transformer model. The experiments systematically tested combinations of entropy regularization, MaxSup penalty, temperature scaling, and logit normalization.

**Note:** This summary is based on the **overnight experiments** (`run_overnight_experiments.py`), which tested **regularization hyperparameters**. This is separate from `hyperparameter_sweep.py`, which tests **architecture/training hyperparameters** (learning_rate, num_layers, loss.temperature). These two sweeps are complementary and should be run sequentially:
1. **Overnight experiments** (completed): Find optimal regularization settings
2. **Hyperparameter sweep** (next step): Test architecture/training parameters using best regularization settings

### Key Findings

- **Best Test KL Divergence:** `combo_4_aggressive` (0.3260) - but with highest validation loss (0.4496)
- **Best Balanced Performance:** `combo_2_all_reductions` (KL: 0.3365, Val Loss: 0.3802)
- **Most Stable:** `combo_6_balanced` (KL: 0.3504, Val Loss: 0.3570)
- **Entropy regularization reduction** is the most impactful single change
- **Temperature reduction** (4.0 ‚Üí 2.0) significantly improves KL divergence
- **MaxSup removal** alone shows minimal improvement

---

## Baseline Configuration

The baseline model configuration (`models/config.yaml`) uses:

| Parameter | Baseline Value | Purpose |
|-----------|---------------|---------|
| `entropy_weight` | 5.0 | Entropy regularization weight |
| `min_entropy` | 1.5 | Minimum entropy threshold |
| `maxsup_weight` | 0.1 | MaxSup penalty weight |
| `temperature` | 4.0 | Temperature scaling for logits |
| `logit_norm` | 1.0 | Target L2 norm for logits |
| `learning_rate` | 0.0001 | Learning rate |

**Problem:** The baseline was producing uniform predictions (mode collapse), indicating over-regularization.

---

## Experiment Results

### 1. combo_6_balanced ‚≠ê‚≠ê‚≠ê (BEST BET)

**Description:** Balanced approach with moderate changes

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **1.0**
- `min_entropy`: 1.5 ‚Üí **0.8**
- `maxsup_weight`: 0.1 ‚Üí **0.0** (disabled)
- `temperature`: 4.0 ‚Üí **2.5**
- `logit_norm`: 1.0 ‚Üí **1.8**

**Results:**
- **Best Validation Loss:** 0.3570
- **Test KL Divergence:** 0.3504
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~37 minutes

**Evaluation:** Most balanced performance with good validation loss and reasonable KL divergence. Safe, moderate changes that avoid overfitting.

---

### 2. combo_2_all_reductions ‚≠ê‚≠ê (ALL RECOMMENDED CHANGES)

**Description:** All recommended fixes combined

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **0.5**
- `min_entropy`: 1.5 ‚Üí **0.5**
- `maxsup_weight`: 0.1 ‚Üí **0.0** (disabled)
- `temperature`: 4.0 ‚Üí **2.0**
- `logit_norm`: 1.0 ‚Üí **2.0**

**Results:**
- **Best Validation Loss:** 0.3802
- **Test KL Divergence:** 0.3365 ‚≠ê (2nd best)
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~22 minutes

**Evaluation:** Excellent KL divergence improvement while maintaining reasonable validation loss. Strong candidate for hyperparameter sweep starting point.

---

### 3. combo_1_entropy_maxsup ‚≠ê‚≠ê (KEY COMBINATION)

**Description:** Reduce entropy + disable MaxSup (two most important fixes)

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **0.5**
- `min_entropy`: 1.5 ‚Üí **0.5**
- `maxsup_weight`: 0.1 ‚Üí **0.0** (disabled)

**Results:**
- **Best Validation Loss:** 0.3718
- **Test KL Divergence:** 0.3962
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~21 minutes

**Evaluation:** Good validation loss but KL divergence improvement is modest. Shows that entropy reduction alone isn't sufficient without temperature adjustments.

---

### 4. baseline_reduced_entropy ‚≠ê (SIMPLEST FIX)

**Description:** Single most important change - reduce entropy regularization

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **0.5**
- `min_entropy`: 1.5 ‚Üí **0.5**

**Results:**
- **Best Validation Loss:** 0.3874
- **Test KL Divergence:** 0.3977
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~21 minutes

**Evaluation:** Confirms that entropy reduction alone helps but is insufficient. Needs complementary changes (temperature, logit_norm).

---

### 5. combo_3_mild (MILD REDUCTIONS)

**Description:** Safer conservative approach

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **2.0**
- `min_entropy`: 1.5 ‚Üí **1.0**
- `temperature`: 4.0 ‚Üí **3.0**
- `logit_norm`: 1.0 ‚Üí **1.5**

**Results:**
- **Best Validation Loss:** 0.3827
- **Test KL Divergence:** 0.3722
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~2 hours

**Evaluation:** Conservative changes show moderate improvement. Longer runtime suggests slower convergence with milder regularization.

---

### 6. reduced_temperature (TEMPERATURE FIX)

**Description:** Test temperature impact alone

**Parameters:**
- `temperature`: 4.0 ‚Üí **2.0**
- `logit_norm`: 1.0 ‚Üí **2.0**

**Results:**
- **Best Validation Loss:** 0.3980
- **Test KL Divergence:** 0.3463 ‚≠ê (3rd best)
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~3.1 hours

**Evaluation:** Temperature reduction alone significantly improves KL divergence, confirming its importance. However, validation loss is higher, suggesting potential overfitting without entropy regularization adjustments.

---

### 7. no_maxsup (MAXSUP TEST)

**Description:** Test MaxSup impact alone

**Parameters:**
- `maxsup_weight`: 0.1 ‚Üí **0.0** (disabled)

**Results:**
- **Best Validation Loss:** 0.3718
- **Test KL Divergence:** 0.3962
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~22 minutes

**Evaluation:** Removing MaxSup alone shows minimal improvement. Not a critical factor, but removing it helps when combined with other changes.

---

### 8. combo_4_aggressive ‚ö†Ô∏è (AGGRESSIVE)

**Description:** Aggressive reductions - might overfit, tests limits

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **0.1**
- `min_entropy`: 1.5 ‚Üí **0.3**
- `maxsup_weight`: 0.1 ‚Üí **0.0** (disabled)
- `temperature`: 4.0 ‚Üí **1.5**
- `logit_norm`: 1.0 ‚Üí **3.0**
- `learning_rate`: 0.0001 ‚Üí **0.0002** (doubled)

**Results:**
- **Best Validation Loss:** 0.4496 ‚ö†Ô∏è (highest)
- **Test KL Divergence:** 0.3260 ‚≠ê‚≠ê‚≠ê (BEST)
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~22 minutes

**Evaluation:** Best KL divergence but highest validation loss indicates overfitting. The model is too confident (low temperature, minimal entropy regularization). Not recommended as-is, but suggests the direction for improvement.

---

### 9. combo_5_no_entropy_reg ‚ö†Ô∏è (NO ENTROPY REG)

**Description:** Completely disable entropy regularization

**Parameters:**
- `entropy_weight`: 5.0 ‚Üí **0.0** (disabled)
- `temperature`: 4.0 ‚Üí **2.0**
- `logit_norm`: 1.0 ‚Üí **2.0**

**Results:**
- **Best Validation Loss:** 0.3981
- **Test KL Divergence:** 0.3464
- **Test Top-1 Accuracy:** 34.84%
- **Test Top-3 Accuracy:** 97.91%
- **Runtime:** ~21 minutes

**Evaluation:** Removing entropy regularization completely shows good KL divergence but higher validation loss. Some entropy regularization is beneficial for preventing overconfidence.

---

## Overall Evaluation

### Performance Ranking (by Test KL Divergence)

| Rank | Experiment | Test KL Divergence | Validation Loss | Status |
|------|------------|-------------------|-----------------|--------|
| 1 | combo_4_aggressive | **0.3260** | 0.4496 ‚ö†Ô∏è | Overfitting |
| 2 | combo_2_all_reductions | **0.3365** | 0.3802 | ‚úÖ Best Balanced |
| 3 | reduced_temperature | **0.3463** | 0.3980 | Good KL, higher val loss |
| 4 | combo_5_no_entropy_reg | **0.3464** | 0.3981 | Good KL, higher val loss |
| 5 | combo_6_balanced | **0.3504** | 0.3570 | ‚úÖ Most Stable |
| 6 | combo_3_mild | **0.3722** | 0.3827 | Moderate improvement |
| 7 | combo_1_entropy_maxsup | **0.3962** | 0.3718 | Modest improvement |
| 8 | no_maxsup | **0.3962** | 0.3718 | Minimal improvement |
| 9 | baseline_reduced_entropy | **0.3977** | 0.3874 | Baseline comparison |

### Key Insights

1. **Temperature Reduction is Critical**
   - Reducing temperature from 4.0 to 2.0 significantly improves KL divergence
   - Best single-parameter change (experiment #6)

2. **Entropy Regularization Balance**
   - Complete removal (0.0) leads to overfitting
   - Too high (5.0 baseline) causes mode collapse
   - Optimal range appears to be 0.5-1.0

3. **MaxSup Impact is Minimal**
   - Removing MaxSup alone shows little improvement
   - Can be safely disabled when combined with other fixes

4. **Logit Normalization Helps**
   - Increasing logit_norm from 1.0 to 2.0 improves performance
   - Works well with temperature reduction

5. **Combined Changes are Most Effective**
   - `combo_2_all_reductions` achieves best balance
   - Multiple complementary changes outperform single-parameter adjustments

6. **Top-1 Accuracy is Consistent**
   - All experiments show identical top-1 accuracy (34.84%)
   - Suggests the model is learning similar patterns regardless of regularization
   - Top-3 accuracy is excellent (97.91%) across all experiments

---

## Recommendations for Hyperparameter Sweep

### Important Distinction

The `hyperparameter_sweep.py` script tests **different parameters** than the overnight experiments:
- **Overnight experiments** (this summary): Regularization parameters (`entropy_weight`, `model.temperature`, `logit_norm`, `maxsup_weight`)
- **Hyperparameter sweep script**: Architecture/training parameters (`learning_rate`, `num_layers`, `loss.temperature`)

**Recommendation:** Update `hyperparameter_sweep.py` to use the best regularization settings from overnight experiments as its baseline, then sweep architecture/training parameters.

### Recommended Starting Point

Use **`combo_2_all_reductions`** regularization settings as the baseline for the architecture/training hyperparameter sweep:

```yaml
loss:
  entropy_weight: 0.5
  min_entropy: 0.5
  maxsup_weight: 0.0

model:
  temperature: 2.0
  logit_norm: 2.0
```

### Hyperparameter Ranges to Explore

#### 1. Entropy Regularization (Priority: HIGH)
- `entropy_weight`: [0.1, 0.3, 0.5, 0.7, 1.0, 1.5]
- `min_entropy`: [0.3, 0.5, 0.7, 0.8, 1.0]

**Rationale:** Critical parameter. Balance between mode collapse (too high) and overfitting (too low).

#### 2. Temperature Scaling (Priority: HIGH)
- `temperature`: [1.5, 2.0, 2.5, 3.0, 3.5]

**Rationale:** Strong impact on KL divergence. Lower values improve predictions but risk overconfidence.

#### 3. Logit Normalization (Priority: MEDIUM)
- `logit_norm`: [1.5, 1.8, 2.0, 2.5, 3.0]

**Rationale:** Complements temperature scaling. Higher values prevent logit explosion.

#### 4. Learning Rate (Priority: MEDIUM)
- `learning_rate`: [0.00005, 0.0001, 0.00015, 0.0002]

**Rationale:** `combo_4_aggressive` used 0.0002. Test if higher LR helps with better regularization.

#### 5. MaxSup (Priority: LOW)
- `maxsup_weight`: [0.0] (keep disabled)

**Rationale:** Minimal impact shown. Can be excluded from sweep.

### Sweep Strategy

1. **Coarse Grid Search** (First Pass)
   - Test wide ranges: entropy_weight [0.1, 0.5, 1.0], temperature [1.5, 2.0, 2.5, 3.0]
   - ~12-16 configurations
   - Identify promising regions

2. **Fine Grid Search** (Second Pass)
   - Narrow around best performers from coarse search
   - Test combinations of top 2-3 values for each parameter
   - ~9-12 configurations

3. **Random Search** (Optional)
   - If computational budget allows
   - Sample from promising regions
   - ~20-30 configurations

### Expected Outcomes

Based on experiments:
- **Best KL Divergence:** ~0.32-0.34 (from `combo_4_aggressive` and `combo_2_all_reductions`)
- **Best Validation Loss:** ~0.35-0.38 (from `combo_6_balanced` and `combo_2_all_reductions`)
- **Optimal Balance:** Likely around entropy_weight=0.3-0.7, temperature=2.0-2.5, logit_norm=1.8-2.5

---

## Recommendations Before Hyperparameter Sweep

### 1. ‚úÖ Model Architecture (No Changes Needed)
- Current architecture (Graph Transformer) is appropriate
- Hidden dimensions, layers, heads appear well-configured

### 2. ‚úÖ Data Augmentation (Keep Enabled)
- Augmentation is enabled and working well
- Current settings (noise_std=0.01, subsample=0.8) are reasonable

### 3. ‚úÖ Training Configuration (Minor Adjustments)
- **Early stopping patience:** Current (5) is good
- **Batch size:** Current (16) is appropriate
- **Gradient clipping:** Current (1.0) prevents logit explosion
- **Consider:** Increase `num_epochs` to 50-100 for hyperparameter sweep to ensure convergence

### 4. ‚ö†Ô∏è Evaluation Metrics (Consider Adding)
- **Current:** KL divergence, top-1/top-3 accuracy
- **Add:**
  - Prediction entropy distribution (to verify mode collapse is fixed)
  - Per-class accuracy breakdown
  - Calibration metrics (expected calibration error)
  - Spatial distribution analysis (are predictions location-specific?)

### 5. ‚úÖ Loss Function (Keep Current)
- Distance-based similarity loss with KL divergence is appropriate
- Current temperature (200m) for distance-to-probability conversion is reasonable

### 6. üìä Monitoring Improvements
- **Add tracking for:**
  - Training/validation entropy over epochs
  - Prediction distribution entropy
  - Max logit values (to detect overconfidence)
  - Gradient norms (to detect training instability)

### 7. üîç Additional Experiments (Optional, Before Sweep)
- **Test different temperature values for distance loss:**
  - Current: 200m
  - Try: [150m, 200m, 250m, 300m]
  - May affect how distance maps to probabilities

- **Test label smoothing:**
  - Currently disabled (0.0)
  - Try small values: [0.05, 0.1]
  - May help with calibration

### 8. ‚úÖ Data Quality (Verify)
- Ensure all neighborhoods are compliant
- Verify feature engineering is consistent
- Check for any data leakage between splits

---

## Next Steps

### Immediate Actions

1. **Set up hyperparameter sweep** using `combo_2_all_reductions` as baseline
2. **Add enhanced monitoring** (entropy tracking, calibration metrics)
3. **Increase training epochs** to 50-100 for sweep experiments
4. **Document sweep results** in similar format to this summary

### Medium-Term Actions

1. **Analyze prediction distributions** from best models
2. **Visualize spatial patterns** in predictions
3. **Test on held-out neighborhoods** (if available)
4. **Compare with baseline** to quantify improvement

### Long-Term Considerations

1. **Ensemble methods** - combine top 3-5 models
2. **Architecture improvements** - if hyperparameter sweep plateaus
3. **Feature engineering** - explore additional spatial features
4. **Transfer learning** - pre-train on larger geographic regions

---

## Conclusion

The overnight experiments successfully identified key parameters affecting mode collapse:

- **Temperature reduction** (4.0 ‚Üí 2.0) is the most impactful single change
- **Entropy regularization** needs careful balancing (optimal: 0.5-1.0)
- **Combined changes** outperform individual parameter adjustments
- **Best balanced performance:** `combo_2_all_reductions` (KL: 0.3365, Val Loss: 0.3802)

The experiments provide a solid foundation for hyperparameter sweep, with clear parameter ranges and expected outcomes. The model is ready for systematic hyperparameter optimization.

---

**Document Generated:** January 20, 2026  
**Based on:** `experiments/overnight_runs/summary.json` and individual experiment results
